* Text Processing

** Words
Sequence of characters with meaning and/or function
** Sentence
Sequence of words with meaning and/or function
** Document
One or more sentences
** Corpus
Collection of documents
** Word Token
Each instance of a word
** Word type
Distinct words
** Why preprocess?
- Most NLP applications have documents as inputs
- **key point:** Language is **compositional.** As humans, we can break these documents
  into individual components. To understand language, a computer should do the same.
- **Preprocessing** is the first step
** Preprocessing steps:
1) Remove unwanted formatting
2) **Sentence segmentation:** break documents into sentences
3) **Word tokenisation:** break sentences into words
4) **Word normalisation:** transform words into canonical forms
5) **Stopword removal:** remove unwanted words

** Sentence segmentation
- Naive approach: break on punctuation
- Use Regex to capture capital
- Have lexicons
- State of the art uses machine learning
*** Binary Classifier
- Looks at every '.' and decides if it is the end of a sentence.
- Features: word shapes(uppercase, lowercase, numbers, ALL_CAPS), words before and after '.', part of speech tags
** Word Tokenisation
 - Naive approach: seperate out alphanumeric strings (\w+)
 - Some asian languages are written without spaces, we need MaxMatch algorithm here where we greedily match longest word in vocab
 - Some languages such as German require compound splitter

** Subword tokenisation
- Colourless green ideas -> [colour] [less] [green] [idea] [s]
- One popular algorithm: byte-pair encoding (BPE)
- Core idea: iteratively merge frequent pair of characters
- Advantage:
  - Data-informed tokenisation
  - Works for different languages
  - Deals better with unknown words
** Word Normalisation
- Lower casing
- Removing morphology (cooking -> cook)
- Correcting spelling
- Expanding Abbreviations
- Goal:
  - Reduce vocabulary
  - Maps words into the same type
** Inflectional Morphology
- Inflectional morphology creates grammatical variants
- English inflects nouns, verbs and adjectives
- Many languages have much richer inflectional morphology
** Lemmatisation
- Lemmatisation means removing any inflection to reach the uninflected form, the lemma
- In English, there are irregularities that prevent a trivial solution:
  - poked -> poke
  - stopping -> stop
  - watches -> watch
** Derivation morphology
- Derivation morphology creates distinct words
- English derivational suffixes often change the lexical category
- English derivational prefixes often change the meaning without changing the lexical category
  - write -> rewrite
  - healthy -> unhealthy
** Stemming
- Stemming strips off all suffixes, leaving a stem
- automate, automatic -> automat
- Even less lexical sparsity than lemmatisation
- Popular in information retrieval
- Stem not always interpretable
** Porter Stemmer
- Word has three forms
  - CVCV...C
  - CVCV...V
  - VCVC...C
  - VCVC...V
  Which can be represented as:
  - [C]VCVC...[V]
  - [C](VC)^m[V]
  - m = **measure**
** Fix Spelling Errors
- Why fix them?
  - Spelling errors create new, rare types
  - Disrupt various kinds of analysis
  - Very common in internet corpus
  - In web search, particularly important in queries
- How?
  - String distance
  - Modelling of error types (phonetic, typing, etc)
  - Use an n-gram language model
** Other word normalisation
 - Normalise spelling variations
 - Expanding abbreviations

** Stopword Removal
- Definition: a list of words to be removed from the document
  - Typical in BOW representations
- How to chose them?
  - All closed-class or function words
  - Any high frequency words
